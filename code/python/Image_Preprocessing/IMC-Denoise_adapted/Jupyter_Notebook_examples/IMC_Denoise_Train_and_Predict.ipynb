{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMC-Denoise: a content aware denoising pipeline to enhance imaging mass cytometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/simon_g/src/MapMet/code/python/Image_Preprocessing/IMC-Denoise_adapted/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will show an example for denoising the images with marker CD38 from our own human bone marrow IMC dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tifffile as tp\n",
    "import random\n",
    "import os\n",
    "import IMC_Denoise\n",
    "from IMC_Denoise.IMC_Denoise_main.DIMR import DIMR\n",
    "from IMC_Denoise.IMC_Denoise_main.DeepSNiF import DeepSNiF\n",
    "from IMC_Denoise.DeepSNiF_utils.DeepSNiF_DataGenerator import DeepSNiF_DataGenerator\n",
    "#print(IMC_Denoise.__dict__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate correct file structure for training\n",
    "First, we will set up the file structure as described below. We will then randomly select one RoI per sample for training of DeepSNiF, since the validation and training is split automatically by the method and we want to avoid that there is a disbalance in ROI selection between samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import tifffile\n",
    "# import xml\n",
    "# import pandas as pd\n",
    "# import io\n",
    "# import random\n",
    "# import shutil\n",
    "\n",
    "# def read_channel_names(path):\n",
    "    \n",
    "#     tiff = tifffile.TiffFile(path)\n",
    "#     omexml_string = tiff.pages[0].description\n",
    "#     root = xml.etree.ElementTree.parse(io.StringIO(omexml_string))\n",
    "#     namespaces = {'ome': 'http://www.openmicroscopy.org/Schemas/OME/2016-06'}\n",
    "#     channels = root.findall('ome:Image[1]/ome:Pixels/ome:Channel', namespaces)\n",
    "#     channel_names = [c.attrib['Name'] for c in channels]\n",
    "#     return channel_names\n",
    "\n",
    "\n",
    "# base_path = \"/data_isilon_main/isilon_images/10_MetaSystems/MetaSystemsData/Multimodal_Imaging_Daria\"\n",
    "\n",
    "# BM_path = os.path.join(base_path, \"BM\")\n",
    "# out_path = os.path.join(base_path, \"_Data_Analysis/_tmp_daria/Image_analysis/20230105_IMC-Denoise\")\n",
    "# marker_codes = pd.read_csv(os.path.join(out_path, 'marker_codes.csv'), sep=\";\")\n",
    "\n",
    "# if not os.path.exists(os.path.join(out_path, \"training\")):\n",
    "#     os.mkdir(os.path.join(out_path, \"training\"))\n",
    "\n",
    "# if not os.path.exists(os.path.join(out_path, \"other\")):\n",
    "#     os.mkdir(os.path.join(out_path, \"other\"))\n",
    "\n",
    "# samples = os.listdir(BM_path)\n",
    "\n",
    "# for s in samples: \n",
    "\n",
    "#     multichannel_path = os.path.join(BM_path, s, \"IF_IMC_lowres\")\n",
    "\n",
    "#     mc_image_files = os.listdir(multichannel_path)\n",
    "\n",
    "#     training_file = random.choice(mc_image_files)\n",
    "#     training_file = training_file.split(\".\")[0]\n",
    "\n",
    "\n",
    "#     for f in mc_image_files:\n",
    "#         file_name = f.split(\".\")[0]\n",
    "\n",
    "#         mc_image = tifffile.imread(os.path.join(multichannel_path, f))\n",
    "\n",
    "#         channel_names = read_channel_names(os.path.join(multichannel_path, f))\n",
    "#         channel_names = pd.DataFrame({'names':channel_names})\n",
    "#         channel_names = channel_names.replace(list(marker_codes[\"old_names\"]), list(marker_codes[\"new_names\"]))\n",
    "\n",
    "#         if file_name == training_file:\n",
    "#             folder = \"training\"\n",
    "#         else:\n",
    "#             folder = \"other\"\n",
    "\n",
    "#         if not os.path.exists(os.path.join(out_path, folder, file_name)):\n",
    "#             os.mkdir(os.path.join(out_path, folder, file_name))\n",
    "\n",
    "#         for c, img in enumerate(mc_image):\n",
    "#             tifffile.imwrite(os.path.join(out_path, folder, file_name, channel_names[\"names\"][c]+\".tiff\"),img)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training data preparation\n",
    "Next, we use our raw images to build a training set.\n",
    "Note: \n",
    "1. The channel name must be consistant with the corresponding channel name in the image file names. For example, in our dataset, CD38 is conjucted with 141Pr. If the images with marker CD38 need to be denoised, the channel name will be set as its isotope name \"141Pr\".\n",
    "2. Raw_directory is the folder of all the raw images used for generating training set. Its subfolders are the imagesets of different tissues. The subfolders contains the images from all the channels of the same tissue. <br>\n",
    "<b>Data_structure example:\n",
    "<br>|---Raw_image_directory\n",
    "<br>|---|---Tissue1\n",
    "<br>|---|---|---Channel1_img.tiff\n",
    "<br>|---|---|---Channel2_img.tiff\n",
    "<br>             ...\n",
    "<br>|---|---|---Channel_n_img.tiff\n",
    "<br>|---|---Tissue2\n",
    "<br>|---|---|---Channel1_img.tiff\n",
    "<br>|---|---|---Channel2_img.tiff\n",
    "<br>             ...\n",
    "<br>|---|---|---Channel_n_img.tiff\n",
    "<br>             ...\n",
    "<br>|---|---Tissue_m\n",
    "<br>|---|---|---Channel1_img.tiff\n",
    "<br>|---|---|---Channel2_img.tiff\n",
    "<br>             ...\n",
    "<br>|---|---|---Channel_n_img.tiff\n",
    "</b>\n",
    "3. n_neighbour and n_lambda are the parameters from DIMR algorithm for hot pixel removal in the training set generation process. 4 and 5 are their defaults. If the defaults are changed, the corresponding parameter should be declared in DeepSNiF_DataGenerator(). Otherwise, they can be omitted.\n",
    "4. The DeepSNiF_DataGenerator class search all the CD38 images in raw image directory, split them into multiple 64x64 patches, and then augment the generated data. Note the very sparse patches are removed in this process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image data loaded from ...\n",
      "\n",
      "/data_isilon_main/isilon_images/10_MetaSystems/MetaSystemsData/Multimodal_Imaging_Daria/_Data_Analysis/_tmp_daria/Image_analysis/20230105_IMC-Denoise/training/20220223_07-1861_BM_R_ROI_003_IF_IMC/150Nd-CD11c_Nd150.tiff\n",
      "/data_isilon_main/isilon_images/10_MetaSystems/MetaSystemsData/Multimodal_Imaging_Daria/_Data_Analysis/_tmp_daria/Image_analysis/20230105_IMC-Denoise/training/20220210_14-0025_BM_ROI_004_IF_IMC/150Nd-CD11c_Nd150.tiff\n",
      "/data_isilon_main/isilon_images/10_MetaSystems/MetaSystemsData/Multimodal_Imaging_Daria/_Data_Analysis/_tmp_daria/Image_analysis/20230105_IMC-Denoise/training/20220215_18-3011_BM_ROI_003_IF_IMC/150Nd-CD11c_Nd150.tiff\n",
      "/data_isilon_main/isilon_images/10_MetaSystems/MetaSystemsData/Multimodal_Imaging_Daria/_Data_Analysis/_tmp_daria/Image_analysis/20230105_IMC-Denoise/training/20211228_04-0968_BM_ROI_001_IF_IMC/150Nd-CD11c_Nd150.tiff\n",
      "/data_isilon_main/isilon_images/10_MetaSystems/MetaSystemsData/Multimodal_Imaging_Daria/_Data_Analysis/_tmp_daria/Image_analysis/20230105_IMC-Denoise/training/20220207_17-2022_BM_ROI_003_IF_IMC/150Nd-CD11c_Nd150.tiff\n",
      "/data_isilon_main/isilon_images/10_MetaSystems/MetaSystemsData/Multimodal_Imaging_Daria/_Data_Analysis/_tmp_daria/Image_analysis/20230105_IMC-Denoise/training/20211229_14-0309_BM_ROI_005_IF_IMC/150Nd-CD11c_Nd150.tiff\n",
      "/data_isilon_main/isilon_images/10_MetaSystems/MetaSystemsData/Multimodal_Imaging_Daria/_Data_Analysis/_tmp_daria/Image_analysis/20230105_IMC-Denoise/training/20220303_18-4528_BM_R_ROI_005_IF_IMC/150Nd-CD11c_Nd150.tiff\n",
      "/data_isilon_main/isilon_images/10_MetaSystems/MetaSystemsData/Multimodal_Imaging_Daria/_Data_Analysis/_tmp_daria/Image_analysis/20230105_IMC-Denoise/training/20220201_06-3859_BM_ROI_002_IF_IMC/150Nd-CD11c_Nd150.tiff\n",
      "/data_isilon_main/isilon_images/10_MetaSystems/MetaSystemsData/Multimodal_Imaging_Daria/_Data_Analysis/_tmp_daria/Image_analysis/20230105_IMC-Denoise/training/20220316_04-0169_BM_N_ROI_002_IF_IMC/150Nd-CD11c_Nd150.tiff\n",
      "/data_isilon_main/isilon_images/10_MetaSystems/MetaSystemsData/Multimodal_Imaging_Daria/_Data_Analysis/_tmp_daria/Image_analysis/20230105_IMC-Denoise/training/20220204_15-2468_BM_ROI_002_IF_IMC/150Nd-CD11c_Nd150.tiff\n",
      "/data_isilon_main/isilon_images/10_MetaSystems/MetaSystemsData/Multimodal_Imaging_Daria/_Data_Analysis/_tmp_daria/Image_analysis/20230105_IMC-Denoise/training/20220112_18-3728_BM_ROI_004_IF_IMC/150Nd-CD11c_Nd150.tiff\n"
     ]
    }
   ],
   "source": [
    "# Release memory\n",
    "if 'generated_patches' in globals():\n",
    "    del generated_patches\n",
    "\n",
    "channel_name = \"150Nd\"\n",
    "base_path = \"/data_isilon_main/isilon_images/10_MetaSystems/MetaSystemsData/Multimodal_Imaging_Daria\"\n",
    "out_path = os.path.join(base_path, \"_Data_Analysis/_tmp_daria/Image_analysis/20230105_IMC-Denoise\")\n",
    "Raw_directory = os.path.join(out_path, \"training\") # change this directory to your Raw_image_directory.\n",
    "\n",
    "n_neighbours = 4 # Larger n enables removing more consecutive hot pixels. \n",
    "n_iter = 3 # Iteration number for DIMR\n",
    "window_size = 3 # Slide window size. For IMC images, window_size = 3 is fine.\n",
    "\n",
    "DataGenerator = DeepSNiF_DataGenerator(channel_name = channel_name, n_neighbours = n_neighbours, n_iter = n_iter, window_size = window_size)\n",
    "generated_patches = DataGenerator.generate_patches_from_directory(load_directory = Raw_directory, n=None)\n",
    "print('The shape of the generated training set is ' + str(generated_patches.shape) + '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Show several generated patches of the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "\n",
    "ax1 = fig.add_subplot(221)\n",
    "im1 = ax1.imshow(generated_patches[0,:,:], cmap = 'jet')\n",
    "divider = make_axes_locatable(ax1)\n",
    "cax = divider.append_axes('right', size='5%', pad=0.05)\n",
    "fig.colorbar(im1, cax=cax, orientation='vertical')\n",
    "\n",
    "ax2 = fig.add_subplot(222)\n",
    "im2 = ax2.imshow(generated_patches[100,:,:], cmap = 'jet')\n",
    "divider = make_axes_locatable(ax2)\n",
    "cax = divider.append_axes('right', size='5%', pad=0.05)\n",
    "fig.colorbar(im2, cax=cax, orientation='vertical')\n",
    "\n",
    "ax3 = fig.add_subplot(223)\n",
    "im3 = ax3.imshow(generated_patches[1000,:,:], cmap = 'jet')\n",
    "divider = make_axes_locatable(ax3)\n",
    "cax = divider.append_axes('right', size='5%', pad=0.05)\n",
    "fig.colorbar(im3, cax=cax, orientation='vertical')\n",
    "\n",
    "ax4 = fig.add_subplot(224)\n",
    "im4 = ax4.imshow(generated_patches[-1,:,:], cmap = 'jet')\n",
    "divider = make_axes_locatable(ax4)\n",
    "cax = divider.append_axes('right', size='5%', pad=0.05)\n",
    "fig.colorbar(im4, cax=cax, orientation='vertical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DeepSNiF configuration and training\n",
    "Define parameters for DeepSNiF training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_patches = generated_patches[:20000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_epoches = 100 # training epoches, which should be about 200 for a good training result. The default is 200.\n",
    "train_initial_lr = 1e-3 # inital learning rate. The default is 1e-3.\n",
    "train_batch_size = 128 # training batch size. For a GPU with smaller memory, it can be tuned smaller. The default is 256.\n",
    "pixel_mask_percent = 0.2 # percentage of the masked pixels in each patch. The default is 0.2.\n",
    "val_set_percent = 0.15 # percentage of validation set. The default is 0.15.\n",
    "loss_function = \"I_divergence\" # loss function used. The default is \"I_divergence\".\n",
    "weights_name = \"weights.hdf5\" # trained network weights saved here. If None, the weights will not be saved.\n",
    "loss_name = \"loss.npz\" # training and validation losses saved here, either .mat or .npz format. If not defined, the losses will not be saved.\n",
    "\n",
    "if not os.path.exists(os.path.join(out_path, \"results\", channel_name)):\n",
    "    os.mkdir(os.path.join(out_path, \"results\", channel_name))\n",
    "weights_save_directory = os.path.join(out_path, \"results\", channel_name) # location where 'weights_name' and 'loss_name' saved.\n",
    "print(weights_save_directory)\n",
    "\n",
    "# If the value is None, the files will be saved in a sub-directory named \"trained_weights\" of  the current file folder.\n",
    "is_load_weights = False # True: load pre-trained weights file from disk for transfer learning and prediction. False: not load any pre-trained weights. \n",
    "lambda_HF = 3e-6 # HF regularization parameter\n",
    "deepsnif = DeepSNiF(train_epoches = train_epoches, \n",
    "                  train_learning_rate = train_initial_lr,\n",
    "                  train_batch_size = train_batch_size,\n",
    "                  mask_perc_pix = pixel_mask_percent,\n",
    "                  val_perc = val_set_percent,\n",
    "                  loss_func = loss_function,\n",
    "                  weights_name = weights_name,\n",
    "                  loss_name = loss_name,\n",
    "                  weights_dir = weights_save_directory, \n",
    "                  is_load_weights = is_load_weights,\n",
    "                  lambda_HF = lambda_HF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start training\n",
    "If errors happen, check if the GPUs are being used by other sessions. If yes, shutdown the session occupying GPUs and re-run the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Consider setting a seed for reproducible results\n",
    "#import tensorflow as tf\n",
    "#tf.random.set_seed(20230105)\n",
    "\n",
    "train_loss, val_loss = deepsnif.train(generated_patches, patience=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the training and validation losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(10, 5))\n",
    "ax.plot(np.array(range(len(train_loss))),train_loss, color='red', marker='^', linewidth=2, markersize=8)\n",
    "ax.plot(np.array(range(len(val_loss))),val_loss, color='blue', marker='o', linestyle='dashed', linewidth=2, markersize=8)\n",
    "ax.set_xlabel('Epoches')\n",
    "ax.set_yscale('log')\n",
    "ax.set_ylabel('BCE losses')\n",
    "ax.legend(['training loss', 'val loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load a raw CD38 image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read a CD38 raw image.\n",
    "unseen = True\n",
    "\n",
    "folder = \"training\"\n",
    "samples = os.listdir(os.path.join(out_path, folder))\n",
    "if unseen: \n",
    "    folder = \"other\"\n",
    "    samples = os.listdir(os.path.join(out_path, folder))\n",
    "\n",
    "index = random.randrange(len(samples))\n",
    "Raw_img_name = os.path.join(out_path, folder, samples[index], \"142Nd-CD11b_Nd142.tiff\") # change to your raw image\n",
    "Img_raw = tp.imread(Raw_img_name)\n",
    "plt.figure(figsize = (10,8))\n",
    "plt.imshow(Img_raw[:100, :100], vmin = 0, vmax = 0.5*np.max(Img_raw), cmap = 'jet')\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "#tifffile.imsave(os.path.join(weights_save_directory, \"raw_example.tiff\"), Img_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform the DIMR algorithm only if the SNR of the raw image is high."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Img_DIMR = DIMR(n_neighbours = n_neighbours, n_iter = n_iter, window_size = window_size).perform_DIMR(Img_raw)\n",
    "plt.figure(figsize = (10,8))\n",
    "plt.imshow(Img_DIMR[:100, :100], vmin = 0, vmax = 0.5*np.max(Img_DIMR), cmap = 'jet')\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "#tifffile.imsave(os.path.join(weights_save_directory, \"DIMR_example.tiff\"), Img_DIMR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If the SNR of the raw image is sub-optimal, perform DIMR and DeepSNiF algorithms for low SNR raw images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform DIMR and DeepSNiF algorithms for low SNR raw images.\n",
    "Img_DIMR_DeepSNiF = deepsnif.perform_IMC_Denoise(Img_raw, n_neighbours = n_neighbours, n_iter = n_iter, window_size = window_size)\n",
    "plt.figure(figsize = (10,8))\n",
    "plt.imshow(Img_DIMR_DeepSNiF[:100, :100], vmin = 0, vmax = 0.5*np.max(Img_DIMR_DeepSNiF), cmap = 'jet')\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "#tifffile.imsave(os.path.join(weights_save_directory, \"DIMR_DeepSNiF_example.tiff\"), Img_DIMR_DeepSNiF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IMC_Denoise",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "227494dca23482e1f70ea6e360c234474a204b47cfdb920bfb24ebedd823d36b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
